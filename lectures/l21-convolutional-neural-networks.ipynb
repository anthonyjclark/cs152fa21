{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afac705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_cifar10_data_loaders,\n",
    "    compute_validation_accuracy_multi,\n",
    "    NN_FC_CrossEntropy,\n",
    "    train_one_epoch,\n",
    ")\n",
    "\n",
    "from fastprogress.fastprogress import master_bar\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ba2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "data_path = \"../data\"\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Hyperparameters (other built in to criterion and optimizer)\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "valid_batch_size = 0\n",
    "\n",
    "# Training device\n",
    "device = \"cpu\" #\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using '{device}' device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data loaders\n",
    "train_loader, valid_loader = get_cifar10_data_loaders(\n",
    "    data_path, batch_size, valid_batch_size\n",
    ")\n",
    "\n",
    "train_loader.dataset.data.shape, valid_loader.dataset.data.shape, train_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how I came up with the normalization values in utils\n",
    "# tl, _ = get_cifar10_data_loaders(data_path, 0, 0)\n",
    "# X, y = next(iter(tl))\n",
    "# X.shape, y.shape\n",
    "# torch.std_mean(X, dim=(0, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64\n",
    "\n",
    "# Grab a bunch of images and change the range to [0, 1]\n",
    "images = torch.tensor(train_loader.dataset.data[:n] / 255)\n",
    "\n",
    "# Create a grid of the images (make_grid expects (BxCxHxW))\n",
    "image_grid = make_grid(images.permute(0, 3, 1, 2))\n",
    "\n",
    "_, axis = plt.subplots(figsize=(16, 16))\n",
    "axis.imshow(image_grid.permute(1, 2, 0))\n",
    "axis.grid(None)\n",
    "\n",
    "targets = train_loader.dataset.targets[:n]\n",
    "classes = train_loader.dataset.classes\n",
    "\n",
    "labels = [f\"{classes[target]:>10}\" for target in targets]\n",
    "\n",
    "images_per_row = int(n ** 0.5)\n",
    "\n",
    "for row in range(images_per_row):\n",
    "    start_index = row * images_per_row\n",
    "    print(\" \".join(labels[start_index : start_index + images_per_row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d8176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Flatten(), nn.Linear(3 * 32 * 32, 10))\n",
    "\n",
    "# nx = torch.prod(torch.tensor(train_loader.dataset.data.shape[1:]))\n",
    "# ny = len(train_loader.dataset.classes)\n",
    "# layer_sizes = (nx, 20, 20, ny)\n",
    "# model = NN_FC_CrossEntropy(layer_sizes, torch.nn.Sigmoid).to(device)\n",
    "\n",
    "model = resnet18(num_classes=10)\n",
    "# model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bbc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = master_bar(range(num_epochs))\n",
    "compute_validation_accuracy_multi(valid_loader, model, criterion, device, mb, 0)\n",
    "for epoch in mb:\n",
    "    train_one_epoch(train_loader, model, criterion, optimizer, device, mb)\n",
    "    loss, accuracy = compute_validation_accuracy_multi(\n",
    "        valid_loader, model, criterion, device, mb, epoch + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = [0] *len(classes)\n",
    "class_total = [0] *len(classes)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, targets in valid_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        predictions = outputs.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        comparisons = predictions.eq(targets.view_as(predictions))\n",
    "        for comp, label in zip(comparisons, targets):\n",
    "            class_correct[label] += comp.item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "        total += targets.shape[0]\n",
    "        correct += int(comparisons.double().sum().item())\n",
    "        \n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on validation set: {correct}/{total} = {accuracy*100:.2f}%\")\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    ccorrect = class_correct[i]\n",
    "    ctotal = class_total[i]\n",
    "    caccuracy = ccorrect / ctotal\n",
    "    print(f\"  Accuracy on {cls:>10} class: {ccorrect}/{ctotal} = {caccuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec690fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import untar_data, URLs, ImageDataLoaders, cnn_learner, xresnet18, accuracy\n",
    "path = untar_data(URLs.CIFAR)\n",
    "dls = ImageDataLoaders.from_folder(path, valid=\"test\", bs=batch_size)\n",
    "learn = cnn_learner(dls, xresnet18, metrics=accuracy)\n",
    "learn.fine_tune(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e02eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
