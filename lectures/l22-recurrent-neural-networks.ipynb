{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d08c513",
   "metadata": {},
   "source": [
    "# Predicting parts of speech with an LSTM\n",
    "\n",
    "Let's preview the end result. We want to take a sentence and output the part of speech for each word in that sentence. Something like this:\n",
    "\n",
    "**Code**\n",
    "\n",
    "```python\n",
    "new_sentence = \"I is a teeth\"\n",
    "\n",
    "...\n",
    "\n",
    "predictions = model(processed_sentence)\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```text\n",
    "I     => Noun\n",
    "is    => Verb\n",
    "a     => Determiner\n",
    "teeth => Noun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b2ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps(s):\n",
    "    \"\"\"Process String: convert a string into a list of lowercased words.\"\"\"\n",
    "    return s.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b2051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://parts-of-speech.info/\n",
    "# Tags:\n",
    "#  D - determiner\n",
    "#  N - noun\n",
    "#  V - verb\n",
    "\n",
    "dataset = [\n",
    "    (ps(\"The dog ate the apple\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Everybody read that book\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Trapp is sleeping\"), [\"N\", \"V\", \"V\"]),\n",
    "    (ps(\"Everybody ate the apple\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Cats are good\"), [\"N\", \"V\", \"D\"]),\n",
    "    (ps(\"Dogs are not as good as cats\"), [\"N\", \"V\", \"D\", \"D\", \"D\", \"D\", \"N\"]),\n",
    "    (ps(\"Dogs eat dog food\"), [\"N\", \"V\", \"N\", \"N\"]),\n",
    "    (ps(\"Watermelon is the best food\"), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (ps(\"I want a milkshake right now\"), [\"N\", \"V\", \"D\", \"N\", \"D\", \"D\"]),\n",
    "    (ps(\"I have too much homework\"), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (ps(\"Zoom won't work\"), [\"N\", \"D\", \"V\"]),\n",
    "    (ps(\"Pie also sounds good\"), [\"N\", \"D\", \"V\", \"D\"]),\n",
    "    (\n",
    "        ps(\"The college is having the department fair this Friday\"),\n",
    "        [\"D\", \"N\", \"V\", \"V\", \"D\", \"N\", \"N\", \"D\", \"N\"],\n",
    "    ),\n",
    "    (ps(\"Research interests span many areas\"), [\"N\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Alex is finishing his Ph.D\"), [\"N\", \"V\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"She is the author\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (\n",
    "        ps(\"It is almost the end of the semester\"),\n",
    "        [\"N\", \"V\", \"D\", \"D\", \"N\", \"D\", \"D\", \"N\"],\n",
    "    ),\n",
    "    (ps(\"Blue is a color\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"They wrote a book\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The syrup covers the pancake\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Harrison has these teeth\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The numbers are fractions\"), [\"D\", \"N\", \"V\", \"N\"]),\n",
    "    (ps(\"Yesterday happened\"), [\"N\", \"V\"]),\n",
    "    (ps(\"Caramel is sweet\"), [\"N\", \"V\", \"D\"]),\n",
    "    (ps(\"Computers use electricity\"), [\"N\", \"V\", \"N\"]),\n",
    "    (ps(\"Gold is a valuable thing\"), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (ps(\"This extension cord helps\"), [\"D\", \"D\", \"N\", \"V\"]),\n",
    "    (ps(\"It works on my machine\"), [\"N\", \"V\", \"D\", \"D\", \"N\"]),\n",
    "    (ps(\"We have the words\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Trapp is a dog\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"This is a computer\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I love lamps\"), [\"N\", \"V\", \"N\"]),\n",
    "    (ps(\"I walked outside\"), [\"N\", \"V\", \"N\"]),\n",
    "    (ps(\"You never bike home\"), [\"N\", \"D\", \"V\", \"N\"]),\n",
    "    (ps(\"You are a wizard Harry\"), [\"N\", \"V\", \"D\", \"N\", \"N\"]),\n",
    "    (ps(\"Trapp ate the shoe\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Jett failed his test\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Alice won the game\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The class lasted a semester\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The tree had a branch\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I ran a race\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The dog barked\"), [\"D\", \"N\", \"V\"]),\n",
    "    (ps(\"Toby hit the wall\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Zayn ate an apple\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The cat fought the dog\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I got an A\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The A hurt\"), [\"D\", \"N\", \"V\"]),\n",
    "    (ps(\"I jump\"), [\"N\", \"V\"]),\n",
    "    (ps(\"I drank a yerb\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The snake ate a fruit\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I played the game\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I watched a movie\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Clark fixed the audio\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I went to Frary\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I go to Pomona\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Food are friends not fish\"), [\"N\", \"V\", \"N\", \"D\", \"N\"]),\n",
    "    (ps(\"You are reading this\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"Wonderland protocol is amazing\"), [\"D\", \"N\", \"V\", \"D\"]),\n",
    "    (ps(\"This is a sentence\"), [\"D\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I should be doing homework\"), [\"N\", \"V\", \"V\", \"V\", \"N\"]),\n",
    "    (ps(\"Computers are tools\"), [\"N\", \"V\", \"N\"]),\n",
    "    (ps(\"The whale swims\"), [\"D\", \"N\", \"V\"]),\n",
    "    (ps(\"A cup is filled\"), [\"D\", \"N\", \"V\", \"V\"]),\n",
    "    (ps(\"This is a cat\"), [\"D\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"These are trees\"), [\"D\", \"V\", \"N\"]),\n",
    "    (ps(\"The cat is the teacher\"), [\"D\", \"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"I ate food today\"), [\"N\", \"V\", \"N\", \"N\"]),\n",
    "    (ps(\"I am a human\"), [\"N\", \"V\", \"D\", \"N\"]),\n",
    "    (ps(\"The cat sleeps\"), [\"D\", \"N\", \"V\"]),\n",
    "    (ps(\"Whales are mammals\"), [\"N\", \"V\", \"N\"]),\n",
    "    (ps(\"I like turtles\"), [\"N\", \"V\", \"N\"]),\n",
    "    (ps(\"A shark ate me\"), [\"D\", \"N\", \"V\", \"N\"]),\n",
    "    (ps(\"There are mirrors\"), [\"D\", \"V\", \"N\"]),\n",
    "    (ps(\"The bus spins\"), [\"D\", \"N\", \"V\"]),\n",
    "    (ps(\"Computers are machines\"), [\"N\", \"V\", \"N\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699caa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855326b",
   "metadata": {},
   "source": [
    "## Preparing data for use as NN input\n",
    "\n",
    "We can't pass a list of plain text words and tags to a NN. We need to convert them to a more appropriate format.\n",
    "\n",
    "We'll start by creating a unique index for each word and tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e114fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "tag_to_index = {}\n",
    "\n",
    "total_words = 0\n",
    "total_tags = 0\n",
    "\n",
    "tag_list = []\n",
    "\n",
    "for words, tags in dataset:\n",
    "\n",
    "    assert len(words) == len(tags)\n",
    "\n",
    "    total_words += len(words)\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "\n",
    "    total_tags += len(tags)\n",
    "\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_index:\n",
    "            tag_to_index[tag] = len(tag_to_index)\n",
    "            tag_list.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a91d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Vocabulary Indices\n",
      "-------------------------------\n",
      "             a => 23\n",
      "          alex => 48\n",
      "         alice => 106\n",
      "        almost => 55\n",
      "          also => 35\n",
      "            am => 160\n",
      "       amazing => 147\n",
      "            an => 121\n",
      "         apple =>  3\n",
      "           are => 12\n",
      "         areas => 47\n",
      "            as => 16\n",
      "           ate =>  2\n",
      "         audio => 136\n",
      "        author => 53\n",
      "        barked => 116\n",
      "            be => 150\n",
      "          best => 20\n",
      "          bike => 98\n",
      "          blue => 59\n",
      "          book =>  7\n",
      "        branch => 113\n",
      "           bus => 171\n",
      "       caramel => 74\n",
      "           cat => 122\n",
      "          cats => 11\n",
      "         clark => 134\n",
      "         class => 109\n",
      "       college => 37\n",
      "         color => 60\n",
      "      computer => 91\n",
      "     computers => 76\n",
      "          cord => 83\n",
      "        covers => 64\n",
      "           cup => 155\n",
      "    department => 39\n",
      "           dog =>  1\n",
      "          dogs => 14\n",
      "         doing => 151\n",
      "         drank => 127\n",
      "           eat => 17\n",
      "   electricity => 78\n",
      "           end => 56\n",
      "     everybody =>  4\n",
      "     extension => 82\n",
      "        failed => 104\n",
      "          fair => 40\n",
      "        filled => 156\n",
      "     finishing => 49\n",
      "          fish => 143\n",
      "         fixed => 135\n",
      "          food => 18\n",
      "        fought => 123\n",
      "     fractions => 71\n",
      "         frary => 139\n",
      "        friday => 42\n",
      "       friends => 142\n",
      "         fruit => 130\n",
      "          game => 108\n",
      "            go => 140\n",
      "          gold => 79\n",
      "          good => 13\n",
      "           got => 124\n",
      "           had => 112\n",
      "      happened => 73\n",
      "      harrison => 66\n",
      "         harry => 101\n",
      "           has => 67\n",
      "          have => 27\n",
      "        having => 38\n",
      "         helps => 84\n",
      "           his => 50\n",
      "           hit => 118\n",
      "          home => 99\n",
      "      homework => 30\n",
      "         human => 161\n",
      "          hurt => 125\n",
      "             i => 21\n",
      "     interests => 44\n",
      "            is =>  9\n",
      "            it => 54\n",
      "          jett => 103\n",
      "          jump => 126\n",
      "         lamps => 93\n",
      "        lasted => 110\n",
      "          like => 165\n",
      "          love => 92\n",
      "       machine => 88\n",
      "      machines => 173\n",
      "       mammals => 164\n",
      "          many => 46\n",
      "            me => 168\n",
      "     milkshake => 24\n",
      "       mirrors => 170\n",
      "         movie => 133\n",
      "          much => 29\n",
      "            my => 87\n",
      "         never => 97\n",
      "           not => 15\n",
      "           now => 26\n",
      "       numbers => 70\n",
      "            of => 57\n",
      "            on => 86\n",
      "       outside => 95\n",
      "       pancake => 65\n",
      "          ph.d => 51\n",
      "           pie => 34\n",
      "        played => 131\n",
      "        pomona => 141\n",
      "      protocol => 146\n",
      "          race => 115\n",
      "           ran => 114\n",
      "          read =>  5\n",
      "       reading => 144\n",
      "      research => 43\n",
      "         right => 25\n",
      "      semester => 58\n",
      "      sentence => 148\n",
      "         shark => 167\n",
      "           she => 52\n",
      "          shoe => 102\n",
      "        should => 149\n",
      "      sleeping => 10\n",
      "        sleeps => 162\n",
      "         snake => 129\n",
      "        sounds => 36\n",
      "          span => 45\n",
      "         spins => 172\n",
      "         sweet => 75\n",
      "         swims => 154\n",
      "         syrup => 63\n",
      "       teacher => 158\n",
      "         teeth => 69\n",
      "          test => 105\n",
      "          that =>  6\n",
      "           the =>  0\n",
      "         there => 169\n",
      "         these => 68\n",
      "          they => 61\n",
      "         thing => 81\n",
      "          this => 41\n",
      "            to => 138\n",
      "          toby => 117\n",
      "         today => 159\n",
      "           too => 28\n",
      "         tools => 152\n",
      "         trapp =>  8\n",
      "          tree => 111\n",
      "         trees => 157\n",
      "       turtles => 166\n",
      "           use => 77\n",
      "      valuable => 80\n",
      "        walked => 94\n",
      "          wall => 119\n",
      "          want => 22\n",
      "       watched => 132\n",
      "    watermelon => 19\n",
      "            we => 89\n",
      "          went => 137\n",
      "         whale => 153\n",
      "        whales => 163\n",
      "        wizard => 100\n",
      "           won => 107\n",
      "         won't => 32\n",
      "    wonderland => 145\n",
      "         words => 90\n",
      "          work => 33\n",
      "         works => 85\n",
      "         wrote => 62\n",
      "          yerb => 128\n",
      "     yesterday => 72\n",
      "           you => 96\n",
      "          zayn => 120\n",
      "          zoom => 31\n",
      "\n",
      "Total number of words: 308\n",
      "Number of unique words: 174\n"
     ]
    }
   ],
   "source": [
    "print(\"       Vocabulary Indices\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "for word in sorted(word_to_index):\n",
    "    print(f\"{word:>14} => {word_to_index[word]:>2}\")\n",
    "\n",
    "print(\"\\nTotal number of words:\", total_words)\n",
    "print(\"Number of unique words:\", len(word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8220a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag Indices\n",
      "-----------\n",
      "  D => 0\n",
      "  N => 1\n",
      "  V => 2\n",
      "\n",
      "Total number of tags: 308\n",
      "Number of unique tags: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag Indices\")\n",
    "print(\"-----------\")\n",
    "\n",
    "for tag, index in tag_to_index.items():\n",
    "    print(f\"  {tag} => {index}\")\n",
    "\n",
    "print(\"\\nTotal number of tags:\", total_tags)\n",
    "print(\"Number of unique tags:\", len(tag_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833357a4",
   "metadata": {},
   "source": [
    "## Letting the NN parameterize words\n",
    "\n",
    "Once we have a unique identifier for each word, it is useful to start our NN with an [embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding) layer. This layer converts an index into a vector of values.\n",
    "\n",
    "You can think of each value as indicating something about the word. For example, maybe the first value indicates how much a word conveys happiness vs sadness. Of course, the NN can learn any attributes and it is not limited to thinks like happy/sad, masculine/feminine, etc.\n",
    "\n",
    "**Creating an embedding layer**. An embedding layer is created by telling it the size of the vocabulary (the number of words) and an embedding dimension (how many values to use to represent a word).\n",
    "\n",
    "**Embedding layer input and output**. An embedding layer takes an index and return a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a695b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_index_tensor(words, mapping):\n",
    "    indices = [mapping[w] for w in words]\n",
    "    return torch.tensor(indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20c8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_index)\n",
    "embed_dim = 6  # Hyperparameter\n",
    "embed_layer = torch.nn.Embedding(vocab_size, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24739098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]),\n",
       " torch.Size([5, 6]),\n",
       " tensor([[-0.9313, -0.1661,  0.0761, -0.5242, -1.7098,  0.2623],\n",
       "         [ 0.2071, -2.9257, -0.9609, -0.9969, -0.6059, -0.4376],\n",
       "         [ 1.5454, -0.6445, -1.3544,  0.2285, -1.0117,  0.6579],\n",
       "         [-0.9313, -0.1661,  0.0761, -0.5242, -1.7098,  0.2623],\n",
       "         [ 0.1930,  0.6564,  1.0926,  0.3456,  0.8239,  1.5447]],\n",
       "        grad_fn=<EmbeddingBackward>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = torch.tensor([word_to_index[\"the\"], word_to_index[\"dog\"]])\n",
    "indices = convert_to_index_tensor(ps(\"The dog ate the apple\"), word_to_index)\n",
    "embed_output = embed_layer(indices)\n",
    "indices.shape, embed_output.shape, embed_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e167a05",
   "metadata": {},
   "source": [
    "## Adding an LSTM layer\n",
    "\n",
    "The [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) layer is in charge of processing embeddings such that the network can output the correct classification. Since this is a recurrent layer, it will take into account past words when it creates an output for the current word.\n",
    "\n",
    "**Creating an LSTM layer**. To create an LSTM you need to tell it the size of its input (the size of an embedding) and the size of its internal cell state.\n",
    "\n",
    "**LSTM layer input and output**. An LSTM takes an embedding (and optionally an initial hidden and cell state) and outputs a value for each word as well as the current hidden and cell state).\n",
    "\n",
    "If you read the linked LSTM documentation you will see that it requires input in this format: (seq_len, batch, input_size)\n",
    "\n",
    "As you can see above, our embedding layer outputs something that is (seq_len, input_size). So, we need to add a dimension in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4284a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 10  # Hyperparameter\n",
    "num_layers = 5  # Hyperparameter\n",
    "lstm_layer = torch.nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486bb0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The LSTM layer expects the input to be in the shape (L, N, E)\n",
    "#   L is the length of the sequence\n",
    "#   N is the batch size (we'll stick with 1 here)\n",
    "#   E is the size of the embedding\n",
    "lstm_output, _ = lstm_layer(embed_output.unsqueeze(1))\n",
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655160d",
   "metadata": {},
   "source": [
    "## Classifiying the LSTM output\n",
    "\n",
    "We can now add a fully connected, [linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layer to our NN to learn the correct part of speech (classification).\n",
    "\n",
    "**Creating a linear layer**. We create a linear layer by specifying the shape of the input into the layer and the number of neurons in the linear layer.\n",
    "\n",
    "**Linear layer input and output**. The input is expected to be (input_size, output_size) and the output will be the output of each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75440441",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_size = len(tag_to_index)\n",
    "linear_layer = torch.nn.Linear(hidden_dim, tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefce339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 3]),\n",
       " tensor([[[-0.3187,  0.1737, -0.0734]],\n",
       " \n",
       "         [[-0.3349,  0.1947, -0.0487]],\n",
       " \n",
       "         [[-0.3406,  0.2132, -0.0383]],\n",
       " \n",
       "         [[-0.3419,  0.2269, -0.0340]],\n",
       " \n",
       "         [[-0.3416,  0.2363, -0.0323]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output = linear_layer(lstm_output)\n",
    "linear_output.shape, linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566eb1a2",
   "metadata": {},
   "source": [
    "# Training an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f687b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "valid_percent = 0.2  # Training/validation split\n",
    "\n",
    "embed_dim = 7  # Size of word embedding\n",
    "hidden_dim = 8  # Size of LSTM internal state\n",
    "num_layers = 5  # Number of LSTM layers\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27273ef",
   "metadata": {},
   "source": [
    "## Creating training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f53886c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(dataset)\n",
    "vocab_size = len(word_to_index)  # Number of unique input words\n",
    "tag_size = len(tag_to_index)  # Number of unique output targets\n",
    "\n",
    "# Shuffle the data so that we can split the dataset randomly\n",
    "shuffle(dataset)\n",
    "\n",
    "split_point = int(N * valid_percent)\n",
    "valid_dataset = dataset[:split_point]\n",
    "train_dataset = dataset[split_point:]\n",
    "\n",
    "len(valid_dataset), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69bd9c",
   "metadata": {},
   "source": [
    "## Creating the Parts of Speech LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3293433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POS_LSTM(torch.nn.Module):\n",
    "    \"\"\"Part of Speach LSTM model.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, tag_size):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = torch.nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, tag_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.embed(X)\n",
    "        X, _ = self.lstm(X.unsqueeze(1))\n",
    "        return self.linear(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee5bc3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c09deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(dataset):\n",
    "    \"\"\"A helper function for computing accuracy on the given dataset.\"\"\"\n",
    "    total_words = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence, tags in dataset:\n",
    "            sentence_indices = convert_to_index_tensor(sentence, word_to_index)\n",
    "            tag_scores = model(sentence_indices).squeeze()\n",
    "            predictions = tag_scores.argmax(dim=1)\n",
    "            total_words += len(sentence)\n",
    "            total_correct += sum(t == tag_list[p] for t, p in zip(tags, predictions))\n",
    "\n",
    "    return total_correct / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c875a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy before training : 23.44%\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after training : 59.38%\n"
     ]
    }
   ],
   "source": [
    "model = POS_LSTM(vocab_size, embed_dim, hidden_dim, num_layers, tag_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "mb = master_bar(range(num_epochs))\n",
    "\n",
    "accuracy = compute_accuracy(valid_dataset)\n",
    "print(f\"Validation accuracy before training : {accuracy * 100:.2f}%\")\n",
    "\n",
    "for epoch in mb:\n",
    "\n",
    "    # Shuffle the data for each epoch (stochastic gradient descent)\n",
    "    shuffle(train_dataset)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for sentence, tags in progress_bar(train_dataset, parent=mb):\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentence = convert_to_index_tensor(sentence, word_to_index)\n",
    "        tags = convert_to_index_tensor(tags, tag_to_index)\n",
    "\n",
    "        tag_scores = model(sentence)\n",
    "\n",
    "        loss = criterion(tag_scores.squeeze(), tags)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "accuracy = compute_accuracy(valid_dataset)\n",
    "print(f\"Validation accuracy after training : {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e780e3",
   "metadata": {},
   "source": [
    "## Examining results\n",
    "\n",
    "Here we look at all words that are misclassified by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edc42165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mis-predictions after training on entire dataset\n",
      "     Word      | True Tag | Prediction\n",
      "--------------------------------------\n",
      "       friends |     N    |    D\n",
      "           not |     D    |    N\n",
      "           the |     D    |    N\n",
      "          tree |     N    |    V\n",
      "           had |     V    |    D\n",
      "             a |     D    |    N\n",
      "   electricity |     N    |    D\n",
      "           the |     D    |    N\n",
      "       numbers |     N    |    V\n",
      "           are |     V    |    D\n",
      "           the |     D    |    N\n",
      "            of |     D    |    N\n",
      "           the |     D    |    N\n",
      "           the |     D    |    N\n",
      "           dog |     N    |    V\n",
      "           ate |     V    |    D\n",
      "           the |     D    |    N\n",
      "           the |     D    |    N\n",
      "           bus |     N    |    V\n",
      "         spins |     V    |    D\n",
      "          this |     D    |    N\n",
      "          this |     D    |    N\n",
      "          this |     D    |    N\n",
      "     extension |     D    |    V\n",
      "          cord |     N    |    D\n",
      "         helps |     V    |    N\n",
      "           the |     D    |    N\n",
      "       college |     N    |    V\n",
      "            is |     V    |    D\n",
      "        having |     V    |    N\n",
      "           the |     D    |    N\n",
      "          this |     D    |    N\n",
      "          food |     N    |    D\n",
      "           dog |     N    |    D\n",
      "       mammals |     N    |    D\n",
      "             a |     D    |    N\n",
      "         shark |     N    |    V\n",
      "           ate |     V    |    D\n",
      "          best |     D    |    N\n",
      "          much |     D    |    N\n",
      "      machines |     N    |    D\n",
      "         won't |     D    |    V\n",
      "          work |     V    |    D\n",
      "           the |     D    |    N\n",
      "         class |     N    |    V\n",
      "        lasted |     V    |    D\n",
      "             a |     D    |    N\n",
      "         these |     D    |    N\n",
      "         trees |     N    |    D\n",
      "       outside |     N    |    D\n",
      "     interests |     N    |    V\n",
      "          span |     V    |    D\n",
      "          many |     D    |    N\n",
      "           the |     D    |    N\n",
      "           cat |     N    |    V\n",
      "        sleeps |     V    |    D\n",
      "           the |     D    |    N\n",
      "             a |     N    |    V\n",
      "          hurt |     V    |    D\n",
      "         lamps |     N    |    D\n",
      "             a |     D    |    N\n",
      "           cup |     N    |    V\n",
      "            is |     V    |    D\n",
      "        filled |     V    |    N\n",
      "     finishing |     V    |    D\n",
      "           his |     D    |    N\n",
      "       turtles |     N    |    D\n",
      "         tools |     N    |    D\n",
      "           the |     D    |    N\n",
      "         whale |     N    |    V\n",
      "         swims |     V    |    D\n",
      "         never |     D    |    V\n",
      "          bike |     V    |    D\n",
      "            as |     D    |    N\n",
      "          good |     D    |    N\n",
      "            as |     D    |    N\n",
      "           the |     D    |    N\n",
      "           dog |     N    |    V\n",
      "        barked |     V    |    D\n",
      "      sleeping |     V    |    D\n",
      "            be |     V    |    D\n",
      "         doing |     V    |    N\n",
      "    wonderland |     D    |    N\n",
      "      protocol |     N    |    V\n",
      "            is |     V    |    D\n",
      "       amazing |     D    |    N\n",
      "           the |     D    |    N\n",
      "           cat |     N    |    V\n",
      "        fought |     V    |    D\n",
      "           the |     D    |    N\n",
      "           the |     D    |    N\n",
      "         snake |     N    |    V\n",
      "           ate |     V    |    D\n",
      "             a |     D    |    N\n",
      "           the |     D    |    N\n",
      "         syrup |     N    |    V\n",
      "        covers |     V    |    D\n",
      "           the |     D    |    N\n",
      "         right |     D    |    N\n",
      "           now |     D    |    N\n",
      "            my |     D    |    N\n",
      "           the |     D    |    N\n",
      "           cat |     N    |    V\n",
      "            is |     V    |    D\n",
      "           the |     D    |    N\n",
      "         there |     D    |    N\n",
      "       mirrors |     N    |    D\n",
      "          also |     D    |    V\n",
      "        sounds |     V    |    D\n",
      "          good |     D    |    N\n",
      "      valuable |     D    |    N\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMis-predictions after training on entire dataset\")\n",
    "header = \"Word\".center(14) + \" | True Tag | Prediction\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sentence, tags in dataset:\n",
    "        sentence_indices = convert_to_index_tensor(sentence, word_to_index)\n",
    "        tag_scores = model(sentence_indices)\n",
    "        predictions = tag_scores.squeeze().argmax(dim=1)\n",
    "        for word, tag, pred in zip(sentence, tags, predictions):\n",
    "            if tag != tag_list[pred]:\n",
    "                print(f\"{word:>14} |     {tag}    |    {tag_list[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf48486",
   "metadata": {},
   "source": [
    "## Using the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc88aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I => N\n",
      "is => V\n",
      "a => D\n",
      "teeth => N\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"I is a teeth\"\n",
    "\n",
    "# Convert sentence to lowercase words\n",
    "sentence = new_sentence.lower().split()\n",
    "\n",
    "# Check that each word is in our vocabulary\n",
    "for word in sentence:\n",
    "    assert word in word_to_index\n",
    "\n",
    "# Convert input to a tensor\n",
    "sentence = convert_to_index_tensor(sentence, word_to_index)\n",
    "\n",
    "# Compute prediction\n",
    "predictions = model(sentence)\n",
    "predictions = predictions.squeeze().argmax(dim=1)\n",
    "\n",
    "# Print results\n",
    "for word, tag in zip(new_sentence.split(), predictions):\n",
    "    print(word, \"=>\", tag_list[tag.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03126959",
   "metadata": {},
   "source": [
    "Things to try:\n",
    "\n",
    "- compare with fully connected network\n",
    "- compare with CNN\n",
    "- compare with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d17307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
